Title: Reveal FALESSSS Hidden Information in the Music Scores: Composer Attribution
Team members: Fang-Chieh Chou, Hsiang-Yu Yang, Yi-Hong Kuo

Just like books are usually wrote in characteristic styles that can be used to attribute their authors, music scores contain rich information about the corresponding composers. With modern machine learning methods, it is possible to extract hidden information from the music scores to attribute the responsible composers. An intriguing composer attribution challenge is related to Josquin des Prez, one of the most famous composers during Renaissance. Due to his immense prestige, many anonymous works during that age were misattributed to Josquin. In 336 works attributed to Josquin, only 50 of them has been verified by independent sources (we will refer them the “positive dataset”). For the rest of the works, there is no enough evidence to determine whether or not they were indeed composed by Josquin (referred as the “unclassified dataset”).

In this project, we propose to use machine learning methods to determine which works in the unclassified dataset are composed by Josquin. This question is a typical classification problem: a music score is either composed by Josquin or not. Therefore standard algorithms such as logistic regression. naive bayes, or supported vector machine can be directly applied to the target problem. In collaboration with the Josquin Research Project by Stanford Music Department, we have obtained digitized version of the music scores by Josquin and other composers at the same age. We will use the 50 music scores in the positive dataset and scores by other composer as negative dataset to train and test each of the algorithms listed above, then apply the best algorithm to the unclassified dataset.

Another major challenge in this work is to select a set of features that successfully capture the underlying “composer style” in these music scores. To address this problem, we propose the following possible solutions. First, we may treat each note in a music score as a “word”, then apply text mining method, for example bag-of-words model or k-shingles to extract features from the data. Another more premature idea is to transform a music score consisted by multiple vocal parts into a 2D matrix, where y-axis represent different vocal parts and x-axis represents the time. Each element in the matrix represents the music note at a specified time by one of the vocal part. This process transforms a music score into a matrix “image”. Then common algorithms for image feature extraction such as SIFT  may be directly applied to extract features in music scores. In this project we will systematically test all the different feature selection methods and compare the performance of different algorithm.

With this project, we wish to resolve the long-standing problem of misattributed works of Josquin. More generally, by examining which ones of our features are most  discriminative, our research will help reveal the nature of the underlying “music styles” of composers. Such knowledge will become important foundations for future researches on medieval music.
